{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":99173,"databundleVersionId":11843845,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install ultralytics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import necessary libraries\nimport torch\nimport pandas as pd\nimport numpy as np\n# import matplotlib.pyplot as plt # Can be commented out if not used for visualization\nfrom ultralytics import YOLO\nfrom pathlib import Path\nimport random\nimport csv\nimport os\n\n# Set seeds (using the same seed as the original example)\ntorch.manual_seed(42)\nnp.random.seed(42)\nrandom.seed(42)\nprint(\"Seeds set to 42\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define dataset paths and class information for the 'Synthetic 2 Real 2' challenge\n# Training and validation use synthetic data provided by the competition.\n# Test uses the real-world images provided by the competition.\ndata_yaml_content = f\"\"\"\n# Dataset paths (adjust if your input directory name differs slightly)\ntrain: /kaggle/input/synthetic-2-real-object-detection-challenge-2/Synthetic to Real Object Detection Challenge 2/train/images\nval: /kaggle/input/synthetic-2-real-object-detection-challenge-2/Synthetic to Real Object Detection Challenge 2/val/images\ntest: /kaggle/input/synthetic-2-real-object-detection-challenge-2/Synthetic to Real Object Detection Challenge 2/testImages/images\n\n# Class information\nnc: 1                # number of classes\nnames: ['soup']      # class names (using 'soup' for the soup can)\n\"\"\"\n\n# Write the configuration to data.yaml file in the working directory\nyaml_path = '/kaggle/working/data.yaml'\nwith open(yaml_path, 'w') as file:\n    file.write(data_yaml_content)\n\nprint(f\"data.yaml created at {yaml_path}\")\nprint(\"--- YAML Content ---\")\nprint(data_yaml_content)\nprint(\"--------------------\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Loading pre-trained YOLO model for trainding\nmodel = YOLO(\"yolov8l.pt\")\nprint(\"Loaded pre-trained yolov8l.pt model.\")\n\n# Hyperparameters\nprint(\"Starting model training...\")\nresults = model.train(\n    data=yaml_path,            # Path to the data configuration file\n    epochs=20,                 # Number of training epochs (adjust based on convergence)\n    batch=16,                  # Batch size (adjust based on GPU memory)\n    imgsz=640,                 # Input image size\n    patience=20,               # Early stopping patience (stops if no improvement after N epochs)\n    optimizer='SGD',           # Optimizer (SGD or Adam/AdamW are common)\n    momentum=0.937,            # SGD momentum\n    lr0=0.0005,                # Initial learning rate\n    weight_decay=0.0001,       # Optimizer weight decay\n    cos_lr=True,               # Use cosine learning rate scheduler\n    save_period=-1,            # Save checkpoint frequency (-1 = only save last and best)\n    workers=2,                 # Number of dataloader workers (adjust based on CPU cores)\n\n    # Augmentations (Crucial for Sim2Real - keep or adjust based on experiments)\n    hsv_h=0.015,               # Image HSV-Hue augmentation (fraction)\n    hsv_s=0.7,                 # Image HSV-Saturation augmentation (fraction)\n    hsv_v=0.4,                 # Image HSV-Value augmentation (fraction)\n    flipud=0.5,                # Image flip up-down (probability)\n    fliplr=0.5,                # Image flip left-right (probability)\n    translate=0.1,             # Image translation (+/- fraction)\n    scale=0.5,                 # Image scale (+/- gain)\n    shear=0.01,                # Image shear (+/- deg)\n\n    # Define project and run name (optional, for organization)\n    project='S2R2_Detection',\n    name='yolov8l_run'\n)\n\nprint(\"Training finished.\")\nprint(f\"Best model weights saved to: {results.save_dir}/weights/best.pt\") # Check the actual path from training output","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the best model weights saved during training\ntry:\n    best_model_path = Path(results.save_dir) / 'weights/best.pt'\n    if not best_model_path.exists():\n        print(\"Warning: results.save_dir not found, using default path structure.\")\n        best_model_path = Path('/kaggle/working/runs/detect/yolov8l_run/weights/best.pt')\n\n    print(f\"Loading best model from: {best_model_path}\")\n    model = YOLO(best_model_path)\nexcept Exception as e:\n    print(f\"Error loading best model: {e}\")\n    print(\"Please ensure training completed successfully and the path to best.pt is correct.\")\n\ntest_images_path = \"/kaggle/input/synthetic-2-real-object-detection-challenge-2/Synthetic to Real Object Detection Challenge 2/testImages/images\"\noutput_dir = \"/kaggle/working/predictions/labels\"\nos.makedirs(output_dir, exist_ok=True)\n\nprint(f\"Running predictions on test images from: {test_images_path}\")\nprint(f\"Saving prediction TXT files to: {output_dir}\")\n\ntest_image_files = list(Path(test_images_path).glob(\"*\"))\nprint(f\"Found {len(test_image_files)} items in test directory.\")\n\nallowed_extensions = {'.png', '.jpg', '.jpeg'}\n\nfor img_path in test_image_files:\n    if not img_path.is_file() or img_path.suffix.lower() not in allowed_extensions:\n        print(f\"Skipping non-image file or unsupported extension: {img_path.name}\")\n        continue\n\n    # conf=0.05 is a low threshold, good for competitions to maximize recall.\n    try:\n        results = model.predict(img_path, conf=0.05, augment=True, save_txt=False, save_conf=False) # We'll save manually\n\n        output_txt_path = Path(output_dir) / f\"{img_path.stem}.txt\"\n\n        with open(output_txt_path, \"w\") as f:\n            if results and len(results) > 0:\n                pred_result = results[0]\n                img_height, img_width = pred_result.orig_shape # Get original image dimensions\n\n                if pred_result.boxes is not None and len(pred_result.boxes) > 0:\n                    for box in pred_result.boxes: # Iterate through detected boxes\n                        cls_id = int(box.cls.item())\n                        confidence = float(box.conf.item())\n                        x1, y1, x2, y2 = box.xyxy[0].tolist()\n\n                        x_center = ((x1 + x2) / 2) / img_width\n                        y_center = ((y1 + y2) / 2) / img_height\n                        width = (x2 - x1) / img_width\n                        height = (y2 - y1) / img_height\n\n                        f.write(f\"0 {confidence:.6f} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n\n    except Exception as e:\n        print(f\"Error predicting on image {img_path.name}: {e}\")\n        output_txt_path = Path(output_dir) / f\"{img_path.stem}.txt\"\n        open(output_txt_path, 'w').close()\n\n\nprint(f\"[notice] ✅ Predictions saved as .txt files in: {output_dir}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predictions_to_csv(\n    preds_folder: str = \"/kaggle/working/predictions/labels\",\n    output_csv: str = \"/kaggle/working/submission.csv\", # Standard Kaggle submission filename\n    test_images_folder: str = \"/kaggle/input/synthetic-2-real-object-detection-challenge-2/Synthetic to Real Object Detection Challenge 2/testImages/images\",\n    allowed_extensions: tuple = (\".jpg\", \".png\", \".jpeg\")):\n    \"\"\"\n    Converts YOLO format prediction .txt files into a Kaggle submission CSV.\n\n    Args:\n        preds_folder: Folder containing the prediction .txt files.\n        output_csv: Path to save the final submission CSV file.\n        test_images_folder: Folder containing the original test images (to get all image IDs).\n        allowed_extensions: Tuple of allowed image file extensions.\n    \"\"\"\n    preds_path = Path(preds_folder)\n    test_images_path = Path(test_images_folder)\n\n    test_images_ids = {p.stem for p in test_images_path.glob(\"*\") if p.is_file() and p.suffix.lower() in allowed_extensions}\n    print(f\"Found {len(test_images_ids)} unique image IDs in the test set.\")\n\n    predictions = []\n    predicted_images_ids = set()\n\n    for txt_file in preds_path.glob(\"*.txt\"):\n        image_id = txt_file.stem\n        predicted_images_ids.add(image_id)\n\n        if image_id not in test_images_ids:\n             print(f\"Warning: Found prediction file '{txt_file.name}' which doesn't match any known test image ID. Skipping.\")\n             continue\n\n        with open(txt_file, \"r\") as f:\n            valid_lines = [line.strip() for line in f if len(line.strip().split()) == 6]\n\n        pred_str = \" \".join(valid_lines) if valid_lines else \"no boxes\"\n        predictions.append({\"image_id\": image_id, \"prediction_string\": pred_str})\\\n\n    missing_images_ids = test_images_ids - predicted_images_ids\n    print(f\"Found {len(missing_images_ids)} test images with no corresponding valid predictions (will use 'no boxes').\")\n    for image_id in missing_images_ids:\n        predictions.append({\"image_id\": image_id, \"prediction_string\": \"no boxes\"})\n\n    if not predictions:\n        print(\"Warning: No predictions were processed. Creating an empty submission file.\")\n        submission_df = pd.DataFrame(list(test_images_ids), columns=['image_id'])\n        submission_df['prediction_string'] = 'no boxes'\n    else:\n        submission_df = pd.DataFrame(predictions)\n\n\n    submission_df.to_csv(output_csv, index=False, quoting=csv.QUOTE_MINIMAL)\n\n    print(f\"[notice] ✅ Submission CSV saved to {output_csv}\")\n    print(f\"Total rows in submission file: {len(submission_df)}\")\n    print(\"Sample rows:\")\n    print(submission_df.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions_to_csv()\nprint(\"Submission file generation process complete.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}